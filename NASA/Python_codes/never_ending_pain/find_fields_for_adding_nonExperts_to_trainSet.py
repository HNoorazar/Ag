# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.14.5
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# %% [markdown]
# # Sep 8th. 2022
#
# I had forgotten that ~1800 fields in the ground-truth table used to train MLs included labels from non-experts. Non-experts had done 2 rounds of labeling. 
#
# **Recall:** In the second round I had listed the links on Google Sheets on the second tab and that misled Michael Brady.
#
# The list of labels that includes non-experts' votes are on OneDrive.
#
# ```train_labels.csv``` that include ~1800 fields in it is generated by ```Form_GroundTruth_Labels_experts_and_NESet2.ipynb```

# %%
import pandas as pd
import numpy as np

import os, os.path
import sys

# %%
param_dir = "/Users/hn/Documents/01_research_data/NASA/parameters/"
NE_S2_dir = param_dir + "nonExpert_set2_fields/"
Perry_and_Co_dir = "/Users/hn/Documents/01_research_data/NASA/Perry_and_Co/"
ML_data_dir = "/Users/hn/Documents/01_research_data/NASA/ML_data/"

# %%
train_labels=pd.read_csv(ML_data_dir + "train_labels.csv")
train_labels.shape

# %%
print('Length of train_labels.ID is [{}].'.format(len(train_labels.ID)))
print('Length of unique train_labels.ID is [{}].'.format(len(train_labels.ID.unique())))

# %%
# expert_set1_postmeeting_consensus=pd.read_csv(ML_data_dir+"expert_set1_postmeeting_consensus.csv")
# expert_set1_premeeting_consensus=pd.read_csv(ML_data_dir+"expert_set1_premeeting_consensus.csv")
# expert_set2_premeeting_consensus=pd.read_csv(ML_data_dir+"expert_set2_premeeting_consensus.csv")

# print(len(expert_set1_postmeeting_consensus.ID.unique()))
# print(len(expert_set1_premeeting_consensus.ID.unique()))
# print(len(expert_set2_premeeting_consensus.ID.unique()))

# set1_all_votes=pd.read_csv(Perry_and_Co_dir+"set1_all_votes.csv")
# set2_all_responases_noRepetition=pd.read_csv(Perry_and_Co_dir+"set2_all_responases_noRepetition.csv")

# print (len(set1_all_votes.ID))
# print (len(set1_all_votes.ID.unique()))

# print (len(set2_all_responases_noRepetition.ID))
# print (len(set2_all_responases_noRepetition.ID.unique()))

# set1_2=pd.concat([set1_all_votes, set2_all_responases_noRepetition])
# print (len(set1_2.ID))
# print (len(set1_2.ID.unique()))

# set2_all_responses=pd.read_csv(Perry_and_Co_dir+"set2_all_responses.csv")
# set1_2=pd.concat([set1_all_votes, set2_all_responses])
# print (len(set1_2.ID))
# print (len(set1_2.ID.unique()))

# %%
NE_S2_dir = "/Users/hn/Documents/01_research_data/NASA/parameters/nonExpert_set2_fields/"
f_name = "NE_set2_post_expert_meeting_IDs_Votes_IncludesNA_fromOneDrive_May23.csv"
NE_S2_postExpertMeeting=pd.read_csv(NE_S2_dir+ f_name)

NE_S2_postExpertMeeting=NE_S2_postExpertMeeting[["ID", "HosseinV"]]
NE_S2_postExpertMeeting=NE_S2_postExpertMeeting[NE_S2_postExpertMeeting.HosseinV.isin(["Single", "Double"])]

print (len(NE_S2_postExpertMeeting.ID.unique()))
print (NE_S2_postExpertMeeting.shape)
NE_S2_postExpertMeeting.head(2)

# %%
NE_S2_postExpertMeeting=NE_S2_postExpertMeeting.iloc[:, 0:2]
NE_S2_postExpertMeeting.head(2)

# %%
NE_S2_postExpertMeeting = NE_S2_postExpertMeeting[~NE_S2_postExpertMeeting.ID.isin(list(train_labels))]
NE_S2_postExpertMeeting.shape

# %%
evaluation_set=pd.read_csv(param_dir+"evaluation_set.csv")
print (evaluation_set.shape)
evaluation_set.head(2)

# %%
NE_S2_postExpertMeeting= pd.merge(NE_S2_postExpertMeeting, evaluation_set, on=['ID'], how='left')

# %%
sorted(NE_S2_postExpertMeeting.CropTyp.unique())

# %%
# NE_set2_premeeting_Consensus=pd.read_csv(NE_S2_dir +  "NE_set2_premeeting_Consensus.csv")
# NE_set2_premeeting_Consensus_IDs_Votes_IncludesUnsure = pd.read_csv(NE_S2_dir + 
#                                                     "NE_set2_premeeting_Consensus_IDs_Votes_IncludesUnsure.csv")

# print (NE_set2_premeeting_Consensus.shape)
# print (NE_set2_premeeting_Consensus_IDs_Votes_IncludesUnsure.shape)

# %% [markdown]
# ## Already Created PDF of Non-Expert Survey 2.
#
# ### This is created in "NE_set_2_analysis.ipynb"

# %% [markdown]
# # NE easy Crops
#
# - **Read 6000 fields**
# - **Toss Small fields**
# - **Toss NE Set 2**
# - **Toss Expert Set 1 and 2**
# - **List goddamn Agreements**
# - **List 75% Agreements**
# - **List the rest**

# %% [markdown]
# # Read 6000 fields.

# %%
evaluation_set=pd.read_csv(param_dir+"evaluation_set.csv")
print (len(evaluation_set.ID.unique()), ",", evaluation_set.shape[0])

# %% [markdown]
# # Read Non-Expert Survey 2. Some fields are less than 10 acres!!!!

# %%
f_name = "NE_set2_post_expert_meeting_IDs_Votes_IncludesNA_fromOneDrive_May23.csv"
NE_S2_postExpertMeeting=pd.read_csv(NE_S2_dir+ f_name)

NE_S2_postExpertMeeting=NE_S2_postExpertMeeting[["ID", "HosseinV"]]
NE_S2_postExpertMeeting=NE_S2_postExpertMeeting[NE_S2_postExpertMeeting.HosseinV.isin(["Single", "Double"])]
NE_S2_postExpertMeeting=pd.merge(NE_S2_postExpertMeeting, evaluation_set, on=['ID'], how='left')
print (len(NE_S2_postExpertMeeting.ID.unique()), "," , NE_S2_postExpertMeeting.shape[0])
NE_S2_postExpertMeeting.head(2)

# %%
NE_S2_postExpertMeeting[NE_S2_postExpertMeeting.ExctAcr<=10].shape

# %% [markdown]
# # Expert and Non-Expert votes in train set

# %%
train_labels=pd.read_csv(ML_data_dir + "train_labels.csv")
train_labels=pd.merge(train_labels, evaluation_set, on=['ID'], how='left')
train_labels.shape

# %%
train_labels[train_labels.ExctAcr<=10].shape

# %% [markdown]
# ### Toss Small fields

# %%
evaluation_set=evaluation_set[evaluation_set.ExctAcr>10].copy()
print (len(evaluation_set.ID.unique()),",", evaluation_set.shape[0])

# %% [markdown]
# ### Toss NE Set 2

# %%
evaluation_set=evaluation_set[~evaluation_set.ID.isin(list(NE_S2_postExpertMeeting.ID.unique()))].copy()
evaluation_set.shape

# %%
train_labels_expert = train_labels[~train_labels.ID.isin(list(NE_S2_postExpertMeeting.ID.unique()))]
train_labels_Nonexpert = train_labels[train_labels.ID.isin(list(NE_S2_postExpertMeeting.ID.unique()))]

print (train_labels_expert.shape)
print (train_labels_Nonexpert.shape)

# %% [markdown]
# ### Toss Expert Set 1 and 2

# %%
evaluation_set=evaluation_set[~evaluation_set.ID.isin(list(train_labels.ID.unique()))].copy()
evaluation_set.shape

# %%
evaluation_set_minusTrainLabels=evaluation_set.copy()

# %%
# nonExpert_2605_votes=pd.read_csv(param_dir + "nonExpert_2605_votes.csv")
# nonExpert_2605_votes.shape

# nonExpert_2605_votes[nonExpert_2605_votes.ID.isin(list(train_labels.ID))].shape
# nonExpert_2605_votes.ExctAcr.min()

# nonExpert_2605_votes= nonExpert_2605_votes[~nonExpert_2605_votes.ID.isin(list(train_labels.ID))]
# nonExpert_2605_votes.shape
# evaluation_set[evaluation_set.ID.isin(list(nonExpert_2605_votes.ID.unique()))].shape
# nonExpert_2605_votes[nonExpert_2605_votes.ID.isin(train_labels_Nonexpert.ID.unique())].shape
# A = evaluation_set[~evaluation_set.ID.isin(list(nonExpert_2605_votes.ID.unique()))].copy()
# B = evaluation_set[evaluation_set.ID.isin(list(nonExpert_2605_votes.ID.unique()))].copy()
# print (evaluation_set[evaluation_set.ID.isin(list(nonExpert_2605_votes.ID.unique()))].shape)
# print (evaluation_set[~evaluation_set.ID.isin(list(nonExpert_2605_votes.ID.unique()))].shape)
# print (nonExpert_2605_votes[nonExpert_2605_votes.ID.isin(list(evaluation_set.ID.unique()))].shape)
# print (nonExpert_2605_votes[~nonExpert_2605_votes.ID.isin(list(evaluation_set.ID.unique()))].shape)

# %% [markdown]
# # Read 6000 Responses Carefully. 
# What we have below is copies from ```6000_nonExpert_VoteCount```

# %%
import pandas as pd
import csv

import os, os.path
import sys

# %% [markdown]
#

# %%
param_dir = "/Users/hn/Documents/01_research_data/NASA/parameters/"

# %%
choices_xl = pd.ExcelFile(param_dir + "all_extended.xlsx")
choices_sheet_names = choices_xl.sheet_names  # see all sheet names

response_set_1_xl = pd.ExcelFile(param_dir + "6000responses.xlsx")
response_sheet_names = response_set_1_xl.sheet_names  # see all sheet names

print (choices_sheet_names[:5])
print (response_sheet_names[:5])

# %%
evaluation_set_csv = pd.read_csv(param_dir + "evaluation_set.csv")
evaluation_set_csv.drop(labels=["ExctAcr"], axis='columns', inplace=True)

print (len(evaluation_set_csv.ID))
print (len(evaluation_set_csv.ID.unique()))

# %% [markdown]
# # Read and assemble the choices; i.e. selected fields for survey

# %%
survey_fields = pd.DataFrame()
for a_sheet in choices_sheet_names:
    a_choice_sheet = choices_xl.parse(a_sheet)
    survey_fields = pd.concat([survey_fields, a_choice_sheet])

print (survey_fields.shape)
survey_fields.drop(labels=["ExctAcr"], axis='columns', inplace=True)
print (len(survey_fields.ID))
print (len(survey_fields.ID.unique()))

survey_fields_help = survey_fields.copy()
survey_fields_help = survey_fields_help[evaluation_set_csv.columns].copy()

survey_fields_help.sort_values(by=['ID'], inplace=True)
evaluation_set_csv.sort_values(by=['ID'], inplace=True)

survey_fields_help.reset_index(inplace=True, drop=True)
evaluation_set_csv.reset_index(inplace=True, drop=True)

evaluation_set_csv.equals(survey_fields_help)

# %%
evaluation_set_csv.head(2)

# %% [markdown]
# ## Count number of questions

# %%
question_count = 0

for a_choice_sheet in choices_sheet_names:
    
    # read a damn sheet
    a_choice_sheet = choices_xl.parse(a_choice_sheet)

    # add them to the damn list
    question_count += a_choice_sheet.shape[0]

print('There are [{ques_count}] questions.'.format(ques_count=question_count))

# %% [markdown]
# # Clean Vote count start here:
#
# #### Problems:
#  - In the beginning emails were not collected! (mostly alfalfa and apple?)
#  - There are some Forms that I still do not have access to. Eshwar has not transferred them to Google Drive despite repeated emails.
#  - There are forms with repeated answers and no email.
#  - Min has responded sparsley, mostly no email, and problematic forms. 
#  - Different email for Hossein. Since I was receiving emails after completing forms, I used a fake email!! no, thank you!
#  - Problematic forms were responded by some, and after fix by others. Drop these forms. No, we can read also problematic forms and keep the latest responses. This way we have Kirti's latest responses and Supriya's responses from Problematic forms.
#  - Not much Mike's vote in wheat. 

# %%
## Define the damn NE_Survey1_response dataframe
NE_Survey1_response = pd.DataFrame(columns=['Form', 'Question', 'ID',
                                            "Hossein", "Supriya", "Kirti", "Mike", "Min"], 
                                   index=range(question_count))
NE_Survey1_response.head(1)
curr_row = 0

extended_choices = pd.DataFrame()

###### populate the NE_Survey1_response datafrme

for response_sheet_name in response_sheet_names:
    # If "problem" in the name of sheet, pass:  
    # No, we can read also problematic forms and keep the latest responses. 
    # This way we have Kirti's latest responses and Supriya's responses from Problematic forms.
    #
    #   IF Kirti responded to a problematic sheet, and then to fixed sheet,
    #   Then we have duplicates!!!!!
    #
    # if 'problem' in response_sheet_name.lower():
    #     continue

    # pick up the numeric part of the sheet names
    sheet_numeric_part = response_sheet_name.split()[1]
    
    # Form sheet names of choices excel sheets
    choice_sheet_name = "extended_" + sheet_numeric_part
    
    a_choice_sheet = choices_xl.parse(choice_sheet_name)
    a_response_sheet = response_set_1_xl.parse(response_sheet_name)

    # If no email is recoded, pass. We do not want it
    # a_response_sheet['Email Address'].isnull().any() works as well. 
    # It is an indication that the form did not collect emails! One or all!
    if a_response_sheet['Email Address'].isnull().all():
        continue

    
    # Fix Hossein email. (replace emails by names!)
    a_response_sheet['Email Address'] = a_response_sheet['Email Address'].str.lower()

    a_response_sheet.loc[a_response_sheet['Email Address'].str.contains('noorazar', na=False), 
                         'Email Address']="Hossein"

    a_response_sheet.loc[a_response_sheet['Email Address'].str.contains('kirti', na=False), 
                         'Email Address']="Kirti"

    a_response_sheet.loc[a_response_sheet['Email Address'].str.contains('supriya', na=False), 
                         'Email Address']="Supriya"

    a_response_sheet.loc[a_response_sheet['Email Address'].str.contains('brady', na=False), 
                         'Email Address']="Mike"

    a_response_sheet.loc[a_response_sheet['Email Address'].str.contains('ming', na=False), 
                         'Email Address']="Min"

    # Fix repeated Kirti in one sheet
    #
    #   IF Kirti responded to a problematic sheet, and then responded to the fixed sheet,
    #   Then we have duplicates!!!!!
    #
    latest_Kirti = a_response_sheet[a_response_sheet['Email Address']=="Kirti"].Timestamp.max()
    Kirti = a_response_sheet[a_response_sheet['Email Address']=="Kirti"]
    # The fact that we have "<" below, eliminates to count how many times
    # Kirti has responded. i.e. if there is one response, it will not be dropped!
    bad_index = Kirti[Kirti.Timestamp < latest_Kirti].index
    a_response_sheet.drop(bad_index, inplace=True)

    latest_Hossein = a_response_sheet[a_response_sheet['Email Address']=="Hossein"].Timestamp.max()
    Hossein = a_response_sheet[a_response_sheet['Email Address']=="Hossein"]
    # The fact that we have "<" below, eliminates to count how many times
    # Kirti has responded. i.e. if there is one response, it will not be dropped!
    bad_index = Hossein[Hossein.Timestamp < latest_Hossein].index
    a_response_sheet.drop(bad_index, inplace=True)
    
    
    latest_Supriya = a_response_sheet[a_response_sheet['Email Address']=="Supriya"].Timestamp.max()
    Supriya = a_response_sheet[a_response_sheet['Email Address']=="Supriya"]
    # The fact that we have "<" below, eliminates to count how many times
    # Kirti has responded. i.e. if there is one response, it will not be dropped!
    bad_index = Supriya[Supriya.Timestamp < latest_Supriya].index
    a_response_sheet.drop(bad_index, inplace=True)
    
    latest_Mike = a_response_sheet[a_response_sheet['Email Address']=="Mike"].Timestamp.max()
    Mike = a_response_sheet[a_response_sheet['Email Address']=="Mike"]
    # The fact that we have "<" below, eliminates to count how many times
    # Kirti has responded. i.e. if there is one response, it will not be dropped!
    bad_index = Mike[Mike.Timestamp < latest_Mike].index
    a_response_sheet.drop(bad_index, inplace=True)
    
    latest_Min = a_response_sheet[a_response_sheet['Email Address']=="Min"].Timestamp.max()
    Min = a_response_sheet[a_response_sheet['Email Address']=="Min"]
    # The fact that we have "<" below, eliminates to count how many times
    # Kirti has responded. i.e. if there is one response, it will not be dropped!
    bad_index = Min[Min.Timestamp < latest_Min].index
    a_response_sheet.drop(bad_index, inplace=True)

    if len(a_response_sheet['Email Address']) != len(a_response_sheet['Email Address'].unique()):
        raise ValueError("Something is wrong in email address column")

    # If less than or equal to 2 people responsed, pass. Keep it if 3 people has responded
    # I commented out the following, since some 
    # fucking sheets had problem. So, some people responded to it, but
    # did not respond to fixed Form. And I want to keep as much as possible!
    # i.e. I will keep the problematic forms and keep whatever questions in them.
    # if len(a_response_sheet['Email Address'])<=2:
    #     continue
    
    #
    # drop unwanted opinions, i.e. keep experts opinions
    #
    # a_response_sheet = a_response_sheet[~(a_response_sheet["Email Address"]=="Min")].copy()
    
    for a_col_name in a_response_sheet.columns:
        if "http" in a_col_name:
            question_number = a_col_name.split()[1].split(":")[0]
            currnt_ID = a_choice_sheet.loc[int(question_number)-1, "ID"]
            if currnt_ID in list(NE_Survey1_response.ID):
                curr_idx = NE_Survey1_response[NE_Survey1_response.ID == currnt_ID].index
                
                if "Hossein" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_idx, "Hossein"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Hossein"][a_col_name].values[0]

                if "Supriya" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_idx, "Supriya"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Supriya"][a_col_name].values[0]

                if "Kirti" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_idx, "Kirti"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Kirti"][a_col_name].values[0]
                if "Mike" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_idx, "Mike"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Mike"][a_col_name].values[0]
                
                if "Min" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_idx, "Min"]=a_response_sheet[a_response_sheet["Email Address"] == \
                                                                     "Min"][a_col_name].values[0]
            else:
                NE_Survey1_response.loc[curr_row, "ID"] = currnt_ID
                NE_Survey1_response.loc[curr_row, "Form"] = int(sheet_numeric_part)
                NE_Survey1_response.loc[curr_row, "Question"] = int(question_number)
                
                if "Hossein" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_row, "Hossein"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Hossein"][a_col_name].values[0]

                if "Supriya" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_row, "Supriya"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Supriya"][a_col_name].values[0]

                if "Kirti" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_row, "Kirti"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Kirti"][a_col_name].values[0]
                if "Mike" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_row, "Mike"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Mike"][a_col_name].values[0]
                
                if "Min" in list(a_response_sheet["Email Address"]):
                    NE_Survey1_response.loc[curr_row, "Min"]=a_response_sheet[a_response_sheet["Email Address"]==\
                                                                     "Min"][a_col_name].values[0]
                curr_row += 1

# %%
print (NE_Survey1_response.shape)
NE_Survey1_response.head(2)

# %% [markdown]
# #### Email was not collected for 10 Forms. Drop them.
#
# all alfalfa.

# %%
NE_Survey1_response_noNA = NE_Survey1_response.dropna(how='all', axis='rows');

# %%
NE_Survey1_response_noNA.shape

# %%
missing_from_responses = evaluation_set_csv[~(evaluation_set_csv.ID.isin(list(NE_Survey1_response_noNA.ID)))].copy()
print (missing_from_responses.shape)

missing_from_responses.head(5)

# %%
missing_from_responses.tail(5)

# %%
NE_Survey1_response.dropna(how='all', axis='rows', inplace=True);
NE_Survey1_response.shape

# %% [markdown]
# # Correct the damn responses
#
# 1. We have not been consistent in the Forms!
# 2. The options we gave there was horrible. For example, the options were:
#    - Single Crop
#    - Double Crop
#    - Unsure
#    - Other:
#    
# Convert anything that has ```cover```, ```mustard``` in it to ```double-crop```, single crops are single crops, anything else will be ```Unsure```.
#
# If an answer has any of these pairs in it, it will be labeled as unsure ```[single, double]```, ```[single, cover]```,
# ```[single, mustard]```.

# %%
NE_Survey1_response.Supriya.unique()

# %%
NE_Survey1_response.reset_index(inplace=True, drop=True)

# %%
people = ["Hossein", "Supriya", "Kirti", "Mike", "Min"]

# We need to keep "none" so that we can use it to compute
# majority vote where someone has not responded a Form
NE_Survey1_response[people] = NE_Survey1_response[people].fillna('none')

for idx in NE_Survey1_response.index:
    for person in people:
        if NE_Survey1_response.loc[idx, person] in ["Single Crop", "Double Crop", "Unsure", "none"]:
            continue
            
        if "cover" in NE_Survey1_response.loc[idx, person].lower() or \
           "mustard" in NE_Survey1_response.loc[idx, person].lower():
            NE_Survey1_response.loc[idx, person] = "Double Crop"
        else:
            NE_Survey1_response.loc[idx, person] = "Unsure"
            
NE_Survey1_response.Supriya.unique()

# %% [markdown]
# ## Drop Min

# %%
NE_Survey1_response.drop(labels=["Min"], axis="columns", inplace=True)
people = ["Hossein", "Supriya", "Kirti", "Mike"]

# %%
NE_Survey1_response.tail(5)

# %%
print (evaluation_set.shape)
evaluation_set.head(2)

# %%
print (NE_Survey1_response.shape)
print (NE_Survey1_response[NE_Survey1_response.ID.isin(list(evaluation_set.ID))].shape)

# %%
evaluation_set[~evaluation_set.ID.isin(list(NE_Survey1_response.ID))]

# %%
print (evaluation_set.shape)
print (evaluation_set[evaluation_set.ID.isin(list(missing_from_responses.ID))].shape)
print (1817+380)

# %%
NE_Survey1_response=NE_Survey1_response[NE_Survey1_response.ID.isin(list(evaluation_set.ID.unique()))].copy()
NE_Survey1_response=pd.merge(NE_Survey1_response, evaluation_set, on=['ID'], how='left')
print (NE_Survey1_response.shape)
NE_Survey1_response.head(2)

# %%
(sorted(NE_Survey1_response.CropTyp.unique()))

# %%
# A=pd.read_csv(param_dir+"evaluation_set.csv")
# sorted(A.CropTyp.unique())

# %% [markdown]
# # Check Check Check 
#    **1.  Check Acreage.**
#    
#    **2. Toss Experts and non-experts labels that we already have.**
#    
#    **3. Focus on Easy crops only.**

# %%
# the following list is from the Excel file called "PerrysChoices.xlsx" in
hard_crops = ['bean, dry', 'bean, green', 'buckwheat', 'canola', 
              'carrot', 'triticale', 'market crops', 'grass hay',
              'mint', 'onion', 'barley', 'barley hay',
              'oat hay', 'yellow mustard',
              'corn seed', 'corn, field','corn, sweet',
              'wheat','potato', 'alfalfa seed', 'grass seed', 'bluegrass seed',
              'pea, dry', 'pea, green']
len(hard_crops)

# %%
NE_Survey1_response.ExctAcr.min()

# %%
NE_Survey1_response[NE_Survey1_response.ID.isin(list(train_labels.ID.unique()))].shape

# %%
NE_Survey1_response.shape

# %%
(NE_Survey1_response.groupby(['CropTyp'])['CropTyp'].count())

# %% [markdown]
# # Compute Majority and Final Votes
#
# This is where I diverge from ```6000_nonExpert_VoteCount```. I want to see where there
# are absolute consensus and where there are 75% consensus.

# %%
NE_FinalSurvey = NE_Survey1_response.copy()
NE_FinalSurvey.drop(["Form", "Question"],  axis="columns", inplace=True)
NE_FinalSurvey.reset_index(inplace=True, drop=True)

# %%
import collections

idx=3

answers_set = collections.Counter(NE_FinalSurvey.loc[idx, people].values)
print (answers_set)

print ("---------------------------------------------------------------------------")
print ("Hossein's unique votes are", NE_FinalSurvey.Hossein.unique())
print ("Supriya's unique votes are", NE_FinalSurvey.Supriya.unique())
print ("Mike's unique votes are", NE_FinalSurvey.Mike.unique())
print ("Kirti's unique votes are", NE_FinalSurvey.Kirti.unique())

print ("Kirti's count of None answers is ",NE_FinalSurvey[NE_FinalSurvey.Kirti=="none"].shape[0])
print ("Mike's count of None answers is ", NE_FinalSurvey[NE_FinalSurvey.Mike=="none"].shape[0])

print ("---------------------------------------------------------------------------")
(NE_FinalSurvey.loc[idx, people])

# %% [markdown]
# # Convert Unsure to None

# %%
NE_FinalSurvey.loc[NE_FinalSurvey.Hossein == 'Unsure', 'Hossein']='none'
NE_FinalSurvey.loc[NE_FinalSurvey.Supriya == 'Unsure', 'Supriya']='none'
NE_FinalSurvey.loc[NE_FinalSurvey.Mike == 'Unsure', 'Mike']='none'
NE_FinalSurvey.loc[NE_FinalSurvey.Kirti == 'Unsure', 'Kirti']='none'

# %%
print ("---------------------------------------------------------------------------")
print ("Hossein's unique votes are", len(NE_FinalSurvey.Hossein.unique()))
print ("Supriya's unique votes are", len(NE_FinalSurvey.Supriya.unique()))
print ("Mike's unique votes are", len(NE_FinalSurvey.Mike.unique()))
print ("Kirti's unique votes are", len(NE_FinalSurvey.Kirti.unique()))


# %%
# NE_FinalSurvey = NE_Survey1_response.copy()
# NE_FinalSurvey.drop(["Form", "Question"],  axis="columns", inplace=True)
# NE_FinalSurvey.reset_index(inplace=True, drop=True)

# NE_FinalSurvey.loc[NE_FinalSurvey.Hossein == 'Unsure', 'Hossein']='none'
# NE_FinalSurvey.loc[NE_FinalSurvey.Supriya == 'Unsure', 'Supriya']='none'
# NE_FinalSurvey.loc[NE_FinalSurvey.Mike == 'Unsure', 'Mike']='none'
# NE_FinalSurvey.loc[NE_FinalSurvey.Kirti == 'Unsure', 'Kirti']='none'


# NE_FinalSurvey["Vote"] = "PlaceHolder"

# for idx in NE_FinalSurvey.index:
#     if len(NE_FinalSurvey.loc[idx, people].unique())==1:
#         NE_FinalSurvey.loc[idx, "Vote"]=NE_FinalSurvey.loc[idx, people].unique()[0]+" (absolute consensus)" 
#     else:
#         answers_set=collections.Counter(NE_FinalSurvey.loc[idx, people].values)
#         if answers_set['none']==1:
#             del answers_set['none']
#             if len(answers_set)==1:
#                 NE_FinalSurvey.loc[idx, "Vote"]= list(answers_set.keys())[0]+" (3 consensus - 1 none)"
#             elif len(answers_set)>1:
#                 NE_FinalSurvey.loc[idx, "Vote"]="2 agree - 1 disagree - 1 none"
#         else:
#             NE_FinalSurvey.loc[idx, "Vote"]="disagreement"
            
# NE_FinalSurvey.head(2)

# %%
# sorted (NE_FinalSurvey.Vote.unique())

# %%
#NE_FinalSurvey.groupby(['Vote'])['Vote'].count()

# %%
# NE_FinalSurvey.shape

# %%
1394+15

# %%

# %%
# NE_FinalSurvey.Hossein.unique()

# %%
#     valid_votes = NE_FinalSurvey.loc[idx, people].values != 'none'
#     valid_votes = NE_FinalSurvey.loc[idx, people].values[valid_votes]

#     needed_vote_count = np.floor(len(valid_votes)/2)+1
#     valid_votes_freq = collections.Counter(valid_votes)

#     for key, value in valid_votes_freq.items():
#         if value>=needed_vote_count:
#             NE_FinalSurvey.loc[idx, "Vote"] = key
            
# NE_Survey1_response.head(2)

# %%
NE_FinalSurvey = NE_Survey1_response.copy()
NE_FinalSurvey.drop(["Form", "Question"],  axis="columns", inplace=True)
NE_FinalSurvey.reset_index(inplace=True, drop=True)

NE_FinalSurvey.loc[NE_FinalSurvey.Hossein == 'Unsure', 'Hossein']='none'
NE_FinalSurvey.loc[NE_FinalSurvey.Supriya == 'Unsure', 'Supriya']='none'
NE_FinalSurvey.loc[NE_FinalSurvey.Mike == 'Unsure', 'Mike']='none'
NE_FinalSurvey.loc[NE_FinalSurvey.Kirti == 'Unsure', 'Kirti']='none'

NE_FinalSurvey["Vote"] = "PlaceHolder"

for idx in NE_FinalSurvey.index:
    # consensus
    if len(NE_FinalSurvey.loc[idx, people].unique())==1:
        NE_FinalSurvey.loc[idx, "Vote"]= "4 agree: "+ NE_FinalSurvey.loc[idx, people].unique()[0] 
        
    # Two types of votes:
    elif len(NE_FinalSurvey.loc[idx, people].unique())==2:
        answers_set=collections.Counter(NE_FinalSurvey.loc[idx, people].values)
        if answers_set['Single Crop']==3 or answers_set['Double Crop']==3:
            NE_FinalSurvey.loc[idx, "Vote"]="3 agree: " + answers_set.most_common(1)[0][0]
        else:
            NE_FinalSurvey.loc[idx, "Vote"]="disagreement"
    # otherwise, three types of votes or more.
    else:
        answers_set=collections.Counter(NE_FinalSurvey.loc[idx, people].values)
        NE_FinalSurvey.loc[idx, "Vote"]="disagreement"
#         if answers_set['none']==1:
#             del answers_set['none']
#             if len(answers_set)>1:
#                 NE_FinalSurvey.loc[idx, "Vote"]="2 agree - 1 disagree - 1 none"
#         else:
#             NE_FinalSurvey.loc[idx, "Vote"]="disagreement"
            
out_dir = "/Users/hn/Documents/01_research_data/NASA/parameters/NE_final_survey/"
out_name = out_dir + "pre_NE_FinalSurvey_EAD_Sept15.csv"
NE_FinalSurvey.to_csv(out_name, index = False)

# %%

# %%
NE_FinalSurvey.groupby(['Vote'])['Vote'].count()

# %%
print (NE_FinalSurvey[NE_FinalSurvey.Vote=="4 agree: Single Crop"].Hossein.unique())
print (NE_FinalSurvey[NE_FinalSurvey.Vote=="4 agree: Single Crop"].Kirti.unique())
print (NE_FinalSurvey[NE_FinalSurvey.Vote=="4 agree: Single Crop"].Supriya.unique())
print (NE_FinalSurvey[NE_FinalSurvey.Vote=="4 agree: Single Crop"].Mike.unique())
print ("------------------------")
print (NE_FinalSurvey[NE_FinalSurvey.Vote=="4 agree: Double Crop"].Hossein.unique())
print (NE_FinalSurvey[NE_FinalSurvey.Vote=="4 agree: Double Crop"].Kirti.unique())
print (NE_FinalSurvey[NE_FinalSurvey.Vote=="4 agree: Double Crop"].Supriya.unique())
print (NE_FinalSurvey[NE_FinalSurvey.Vote=="4 agree: Double Crop"].Mike.unique())


# %%
1394+15

# %%
228+39

# %% [markdown]
# # Drop agreements
# so we can create Google Forms for final survey

# %%
NE_FinalSurvey.head(2)

# %%
NE_FinalSurvey.Vote.unique()

# %%
easyVI_preMeeting_Agreement=NE_FinalSurvey[NE_FinalSurvey.Vote.isin(["4 agree: Single Crop", "4 agree: Double Crop"])]
easyVI_disagreements=NE_FinalSurvey[~NE_FinalSurvey.Vote.isin(["4 agree: Single Crop", "4 agree: Double Crop"])]

# %%
NE_FinalSurvey.shape[0]==easyVI_preMeeting_Agreement.shape[0]+easyVI_disagreements.shape[0]

# %%
out_dir = "/Users/hn/Documents/01_research_data/NASA/parameters/NE_final_survey/"

out_name = out_dir + "easyVI_preMeeting_Agreements_Sept15.csv"
easyVI_preMeeting_Agreement.to_csv(out_name, index = False)

# %%
easyVI_disagreements.Vote.unique()

# %%
easyVI_disagreements.head(2)

# %% [markdown]
# # We need to have file names to create Google Forms,

# %%
Eshwar_Extensive=pd.read_csv(param_dir+"Eshwar_Extensive.csv")
print (Eshwar_Extensive.shape)
Eshwar_Extensive.head(2)

# %% [markdown]
# #### We need also to sort columns so that we can use old code for generating the Google Forms

# %%
# nonExpert_survey2_fields = pd.read_csv(NE_S2_dir+"nonExpert_survey2_fields.csv")
# needed_cols=nonExpert_survey2_fields.columns
# needed_cols

# %%
new_cols = ["ID", "Hossein", "Supriya", "Kirti", "Mike", "Vote"]
easyVI_disagreements_forFinalSurvey=pd.merge(easyVI_disagreements[new_cols],
                                             Eshwar_Extensive[["ID", "NDVI_TS_Name", 
                                                               "latitude", "longitude", "county",
                                                               "ExctAcr", "DataSrc", "Irrigtn", 
                                                               "CropTyp"]],
                                             on=['ID'], how='left')

# %%
easyVI_disagreements_forFinalSurvey.head(2)

# %%
list(easyVI_disagreements_forFinalSurvey.columns)

# %%
sort_cols = ["ID", "NDVI_TS_Name", "CropTyp", 
             "latitude", "longitude", 'county',
             'ExctAcr', 'DataSrc', 'Irrigtn',
             "Hossein", 'Supriya', 'Kirti', 'Mike', 'Vote',]
easyVI_disagreements_forFinalSurvey=easyVI_disagreements_forFinalSurvey[sort_cols]

easyVI_disagreements_forFinalSurvey.sort_values(by=['Vote', 'CropTyp', 'CropTyp', 'county', "ID"], 
                                                inplace=True)

easyVI_disagreements_forFinalSurvey.head(2)



# %%
out_name = out_dir + "easyVI_disagreements_forFinalSurvey_Sept15.csv"
easyVI_disagreements_forFinalSurvey.to_csv(out_name, index = False)


# %%
easyVI_disagreements_forFinalSurvey.reset_index(inplace=True, drop=True)
easyVI_disagreements_forFinalSurvey.shape

# %% [markdown]
# ### Write the sets in excel format

# %%
no_questions = 50

writer_limited = pd.ExcelWriter(out_dir + 'easyVI_disagreements_forFinalSurvey_Sept15.xlsx', engine='xlsxwriter') 

if easyVI_disagreements_forFinalSurvey.shape[0] % no_questions != 0:
    no_dfs = easyVI_disagreements_forFinalSurvey.shape[0] // no_questions + 1
else:
    no_dfs = easyVI_disagreements_forFinalSurvey.shape[0] // no_questions

for ii in range(no_dfs):
    curr_sheet = easyVI_disagreements_forFinalSurvey.loc[(ii*no_questions): ((ii+1) * no_questions) - 1, ]
    curr_sheet.reset_index(drop=True, inplace=True)
    curr_sheet.to_excel(writer_limited, sheet_name= "final_set_form_" + str(ii+1), index=False)

writer_limited.save()

# %%
easyVI_disagreements_forFinalSurvey.columns

# %%
sorted(easyVI_disagreements_forFinalSurvey.CropTyp.unique())

# %%
sorted(hard_crops)

# %%

# %%

# %% [markdown]
# ####  Are there 38 fields in train_labels.csv that are not among the Expert and NE_S2 fields!!!

# %%
train_labels_38=pd.read_csv(ML_data_dir + "train_labels.csv")
print (train_labels_38.shape)

NE_S2_dir = "/Users/hn/Documents/01_research_data/NASA/parameters/nonExpert_set2_fields/"
f_name = "NE_set2_post_expert_meeting_IDs_Votes_IncludesNA_fromOneDrive_May23.csv"
NE_S2_postExpertMeeting_38=pd.read_csv(NE_S2_dir+ f_name)

NE_S2_postExpertMeeting_38=NE_S2_postExpertMeeting_38[["ID", "HosseinV"]]
E_S1_postmeeting_consensus=pd.read.csv(ML_data_dir+"expert_set1_postmeeting_consensus.csv")
E_S1_premeeting_consensus=pd.read.csv(ML_data_dir+"expert_set1_premeeting_consensus.csv")
E_S2_premeeting_consensus=pd.read.csv(ML_data_dir+"expert_set2_premeeting_consensus.csv")


# %%
train_labels_38[train_labels_38.ID.isin(list(NE_S2_postExpertMeeting_38.ID))].shape

# %%

# %%
for ii in range(10):
    print (ii)

# %%
